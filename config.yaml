MODEL: "local"  # Choose: "api" (OpenAI-compatible), "local" (Ollama), "unified" (LiteLLM for modern APIs), or "anthropic" (Claude SDK)

# =============================================================================
# Modern Model API Configuration (RECOMMENDED)
# =============================================================================
# Use "unified" mode with LiteLLM for all modern APIs including:
# - OpenRouter (access 100+ models through one API)
# - Anthropic Claude (Sonnet 4.5, Opus, Haiku)
# - xAI Grok (Grok-1, Grok-2)
# - OpenAI (GPT-4o, GPT-4 Turbo)
# - Google Gemini (Gemini Pro, Flash)
# - And many more...

UNIFIED_API_KEY: ""  # Your API key for the chosen provider
UNIFIED_MODEL: "claude-sonnet-4-5-20250929"  # Model name (see examples below)
UNIFIED_BASE_URL: ""  # Optional: Custom base URL (e.g., for OpenRouter: "https://openrouter.ai/api/v1")

# =============================================================================
# UNIFIED MODEL EXAMPLES (copy the model name you want to use)
# =============================================================================

# --- OpenRouter (Recommended for accessing multiple models) ---
# UNIFIED_API_KEY: "sk-or-v1-..."  # Get from https://openrouter.ai/keys
# UNIFIED_BASE_URL: "https://openrouter.ai/api/v1"
# UNIFIED_MODEL: "openrouter/anthropic/claude-sonnet-4"  # Claude Sonnet 4
# UNIFIED_MODEL: "openrouter/google/gemini-2.0-flash-exp"  # Gemini 2.0 Flash
# UNIFIED_MODEL: "openrouter/x-ai/grok-2-vision-1212"  # Grok 2 Vision
# UNIFIED_MODEL: "openrouter/openai/gpt-4o"  # GPT-4o
# UNIFIED_MODEL: "openrouter/deepseek/deepseek-chat"  # DeepSeek

# --- Anthropic Claude (Direct API) ---
# UNIFIED_API_KEY: "sk-ant-..."  # Get from https://console.anthropic.com/
# UNIFIED_MODEL: "claude-sonnet-4-5-20250929"  # Latest Sonnet 4.5
# UNIFIED_MODEL: "claude-opus-4-20250514"  # Claude Opus 4
# UNIFIED_MODEL: "claude-3-5-sonnet-20241022"  # Claude 3.5 Sonnet

# --- xAI Grok ---
# UNIFIED_API_KEY: "xai-..."  # Get from https://console.x.ai/
# UNIFIED_MODEL: "xai/grok-beta"  # Grok Beta
# UNIFIED_MODEL: "xai/grok-vision-beta"  # Grok Vision

# --- OpenAI ---
# UNIFIED_API_KEY: "sk-..."  # Get from https://platform.openai.com/api-keys
# UNIFIED_MODEL: "gpt-4o"  # GPT-4 Omni
# UNIFIED_MODEL: "gpt-4o-mini"  # GPT-4 Omni Mini
# UNIFIED_MODEL: "gpt-4-turbo"  # GPT-4 Turbo

# --- Google Gemini ---
# UNIFIED_API_KEY: "..."  # Get from https://aistudio.google.com/app/apikey
# UNIFIED_MODEL: "gemini/gemini-2.0-flash-exp"  # Gemini 2.0 Flash
# UNIFIED_MODEL: "gemini/gemini-pro-vision"  # Gemini Pro Vision

# --- Mistral AI ---
# UNIFIED_API_KEY: "..."  # Get from https://console.mistral.ai/
# UNIFIED_MODEL: "mistral/mistral-large-latest"  # Mistral Large
# UNIFIED_MODEL: "mistral/pixtral-12b-2409"  # Pixtral (vision)

# --- DeepSeek ---
# UNIFIED_API_KEY: "..."  # Get from https://platform.deepseek.com/
# UNIFIED_MODEL: "deepseek/deepseek-chat"  # DeepSeek Chat
# UNIFIED_MODEL: "deepseek/deepseek-reasoner"  # DeepSeek Reasoner

# =============================================================================
# Legacy API Configuration (OpenAI-compatible APIs)
# =============================================================================
API_BASE_URL: "https://api.openai.com/v1/chat/completions"
API_KEY: "sk-"  # Your API key
API_MODEL: "gpt-4o-mini"  # Model name

# =============================================================================
# Anthropic Claude (Official SDK - alternative to unified mode)
# =============================================================================
ANTHROPIC_API_KEY: ""  # Your Anthropic API key
ANTHROPIC_MODEL: "claude-sonnet-4-5-20250929"  # Claude model name

# Local Model Configuration (Ollama)
LOCAL_BASE_URL: "http://localhost:11434/v1/chat/completions"
LOCAL_MODEL: "qwen3-vl:4b"  # Ollama model with vision support (optimized for 16GB RAM)
# Model specs: 4.4B params, 262K context length
# Note: This model uses thinking mode - needs 4096+ tokens for complete responses

# Common Settings
MAX_TOKENS: 4096  # Increased for qwen3-vl:4b thinking mode (model needs space for internal reasoning + final answer)
TEMPERATURE: 0.0  # The temperature of the model: the lower the value, the more consistent the output of the model
REQUEST_INTERVAL: 10  # Time in seconds between consecutive requests

# Android Configuration
ANDROID_SCREENSHOT_DIR: "/sdcard/Pictures"  # Changed from /sdcard to /sdcard/Pictures for Android API 36+ compatibility
ANDROID_XML_DIR: "/sdcard/Documents"  # Changed from /sdcard to /sdcard/Documents for Android API 36+ compatibility
ANDROID_SDK_PATH: ""  # Android SDK path (auto-detected or configured in Electron app Settings)

# Web Configuration (for Playwright-based web automation)
WEB_BROWSER_TYPE: "chromium"  # Browser type: "chromium", "firefox", or "webkit"
WEB_HEADLESS: false  # Run browser in headless mode (no GUI)
WEB_VIEWPORT_WIDTH: 1280  # Browser viewport width
WEB_VIEWPORT_HEIGHT: 720  # Browser viewport height

# Image Optimization (reduces token usage for vision models)
IMAGE_MAX_WIDTH: 512  # Maximum image width for vision model input (reduced for 4b model stability)
IMAGE_MAX_HEIGHT: 512  # Maximum image height for vision model input (reduced for 4b model stability)
IMAGE_QUALITY: 85  # JPEG compression quality (1-100, higher = better quality but larger size)
OPTIMIZE_IMAGES: true  # Enable automatic image optimization to reduce token usage

DOC_REFINE: false  # Set this to true will make the agent refine existing documentation based on the latest demonstration; otherwise, the agent will not regenerate a new documentation for elements with the same resource ID.
MAX_ROUNDS: 20  # Set the round limit for the agent to complete the task
DARK_MODE: false  # Set this to true if your app is in dark mode to enhance the element labeling
MIN_DIST: 30  # The minimum distance between elements to prevent overlapping during the labeling process